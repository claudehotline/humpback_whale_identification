{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import normalize, LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/humpback-whale-identification/train.csv'\n",
    "\n",
    "image_size = 224\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TripletModel, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        \n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.base_model.fc = nn.Linear(2048, embedding_dim=50)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output1 = self.base_model(input[:,0,:,:,:])\n",
    "        output2 = self.base_model(input[:,1,:,:,:])\n",
    "        output3 = self.base_model(input[:,2,:,:,:])\n",
    "        \n",
    "        return output1, output2, output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = np.square(anchor - positive)\n",
    "    negative_distance = np.square(anchor - negative)\n",
    "    \n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = np.sqrt(np.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = np.aqrt(np.sum(negative_distance, axis=-1, keepdims=True))\n",
    "        \n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = np.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = np.sum(negative_distance, axis=-1, keepdims=True)\n",
    "        \n",
    "    loss = positive_distance - negative_distance\n",
    "    \n",
    "    if margin == 'maxplus':\n",
    "        loss = np.maximum(0.0, 1 + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = np.log(1 + np.exp(loss))\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imagename_id_mapping, other_id=\"new_whale\", transform=None):\n",
    "        \n",
    "        self.transforms = transform\n",
    "        \n",
    "        self.train_data, self.train_labels = ...\n",
    "        \n",
    "        # image name ---> class id \n",
    "        self.imagename_id_mapping = imagename_id_mapping\n",
    "        # class id ---> image names\n",
    "        self.id_to_imagenames = defaultdict(list)\n",
    "        # list of new _whale image names\n",
    "        self.new_whale_list = []\n",
    "        # list of all unique image names\n",
    "        self.all_imagenames_list = list(imagename_id_mapping.keys())\n",
    "        # range of number of image names\n",
    "        self.all_imagenames_range = list(range(len(self.all_imagenames_list)))\n",
    "        \n",
    "        self.images, self.labels = torch.load()\n",
    "        \n",
    "        for imagename, id_ in imagename_id_mapping.items():\n",
    "            if id_ == other_id:\n",
    "                self.new_whale_list.append(imagename)\n",
    "            else:\n",
    "                self.id_to_imagenames[id_].append(imagename)\n",
    "            \n",
    "        self.id_list = list(set(self.imagename_id_mapping.values()))\n",
    "        self.all_id_range = range(len(self.id_list))\n",
    "        \n",
    "        self.id_weight = np.array([len(self.id_to_imagenames[id_]) for id_ in self.id_list])\n",
    "        self.id_weight = self.id_weight / np.sum(self.id_weight)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # id_idx = np.random.choice(self.all_id_range, 1, p=self.id_weight)[0]\n",
    "        \n",
    "        examples_id_idx = np.random.choice(range(len(self.id_to_imagenames[self.id_list[idx]])), 2)\n",
    "        \n",
    "        positive_example1 = self.id_to_imagenames[self.id_list[idx]][examples_id_idx[0]]\n",
    "        \n",
    "        positive_example2 = self.id_to_imagenames[self.id_list[idx]][examples_id_idx[1]]\n",
    "        \n",
    "        negative_example = None\n",
    "        \n",
    "        while negative_example is None or self.imagename_id_mapping[negative_example] == \\\n",
    "                                        self.imagename_id_mapping[positive_example1]:\n",
    "            \n",
    "            negative_example_idx = np.random.choice(self.all_imagenames_range, 1)[0]\n",
    "            \n",
    "            negative_example = self.all_imagenames_list[negative_example_idx]\n",
    "            \n",
    "        sample = (positive_example1, negative_example, positive_example2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def make_triplet_list(self, labels):\n",
    "        \n",
    "        print('Processing Triplet Generation ...')\n",
    "        \n",
    "        onehot_labels = prepare_labels(lables)\n",
    "        filename = self.train_triplet_file\n",
    "        \n",
    "        triplets = []\n",
    "        \n",
    "        for class_idx in range(all_id_range):\n",
    "            a = np.random.choice(np.where(onehot_labels == class_idx)[0], self.id_weight, replace=True)\n",
    "            b = np.random.choice(np.where(onehot_labels == class_idx)[0], self.id_weight, replace=True)\n",
    "            \n",
    "            c = np.random.choice(np.where(onehot_labels != class_idx)[0])\n",
    "            \n",
    "            for i in range(a.shape[0]):\n",
    "                triplets.append([int(a[i]), int(c[i]), int(b[i])])\n",
    "                \n",
    "        with open(filename, \"w\") as f:\n",
    "            writer = csv.writeer(f, delimiter=' ')\n",
    "            writer.wirterows(triplets)\n",
    "        print('Done!')\n",
    "        \n",
    "        \n",
    "    def prepare_labels(y):\n",
    "        values = np.array(y)\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(values)\n",
    "        \n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "        \n",
    "        y = onehot_encoded\n",
    "        \n",
    "        return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    \n",
    "    def __init__(self, imagename_id_mapping, other_id=\"new_whale\"):\n",
    "        # image name ---> class id \n",
    "        self.imagename_id_mapping = imagename_id_mapping\n",
    "        # class id ---> image names\n",
    "        self.id_to_imagenames = defaultdict(list)\n",
    "        # list of new _whale image names\n",
    "        self.new_whale_list = []\n",
    "        # list of all unique image names\n",
    "        self.all_imagenames_list = list(imagename_id_mapping.keys())\n",
    "        # range of number of image names\n",
    "        self.all_imagenames_range = list(range(len(self.all_imagenames_list)))\n",
    "        \n",
    "        for imagename, id_ in imagename_id_mapping.items():\n",
    "            if id_ == other_id:\n",
    "                self.new_whale_list.append(imagename)\n",
    "            else:\n",
    "                self.id_to_imagenames[id_].append(imagename)\n",
    "            \n",
    "        self.id_list = list(set(self.imagename_id_mapping.values()))\n",
    "    \n",
    "        self.all_id_range = range(len(self.id_list))\n",
    "        \n",
    "        self.id_weight = np.array([len(self.id_to_imagenames[id_]) for id_ in self.id_list])\n",
    "        \n",
    "        self.id_weight = self.id_weight / np.sum(self.id_weight)\n",
    "        \n",
    "    def get_sample(self):\n",
    "        id_idx = np.random.choice(self.all_id_range, 1, p=self.id_weight)[0]\n",
    "        \n",
    "        examples_id_idx = np.random.choice(range(len(self.id_to_imagenames[self.id_list[id_idx]])), 2)\n",
    "        \n",
    "        positive_example1 = self.id_to_imagenames[self.id_list[id_idx]][examples_id_idx[0]]\n",
    "        \n",
    "        positive_example2 = self.id_to_imagenames[self.id_list[id_idx]][examples_id_idx[1]]\n",
    "        \n",
    "        negative_example = None\n",
    "        \n",
    "        while negative_example is None or self.imagename_id_mapping[negative_example] == \\\n",
    "                                        self.imagename_id_mapping[positive_example1]:\n",
    "            \n",
    "            negative_example_idx = np.random.choice(self.all_imagenames_range, 1)[0]\n",
    "            \n",
    "            negative_example = self.all_imagenames_list[negative_example_idx]\n",
    "            \n",
    "        return positive_example1, negative_example, positive_example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(filepath):\n",
    "    \n",
    "    image = Image.open(filepath).convert('RGB')\n",
    "    \n",
    "    image = image.resize((image_size, image_size))\n",
    "    \n",
    "    return np.array(image, dtype=\"float32\")\n",
    "\n",
    "def augment(image):\n",
    "    \n",
    "    if np.random.uniform(0, 1) > 0.9:\n",
    "        image = np.fliplr(image)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(triplet):\n",
    "    \n",
    "    while True:\n",
    "        positive_example1_list = []\n",
    "        negative_example_list = []\n",
    "        positive_example2_list = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "                \n",
    "            positive_example1, negative_example, positive_example2 = triplet.get_sample()\n",
    "            \n",
    "            pos1_path = join(path_train, positive_example1)\n",
    "            neg_path = join(path_train, negative_example)\n",
    "            pos2_path = join(path_train, positive_example2)\n",
    "            \n",
    "            pos1_image = augment(resize(pos1_path))\n",
    "            neg_image = augment(resize(neg_path))\n",
    "            pos2_image = augment(resize(pos2_path))\n",
    "            \n",
    "            positive_example1_list.append(pos1_image)\n",
    "            negative_example_list.append(neg_image)\n",
    "            positive_example2_list.append(pos2_image)\n",
    "            \n",
    "        label = None\n",
    "            \n",
    "        triplet_inputs = np.array(batch_size, (positive_example1_list, negative_example_list, positive_example2_list))\n",
    "        \n",
    "        yield triplet_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the CSV file and create pytorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH)\n",
    "train, valid = train_test_split(data, train_size=0.7, random_state=1337)\n",
    "\n",
    "imagename_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "imagename_id_mapping_valid = {k: v for k, v in zip(valid.Image.values, valid.Id.values)}\n",
    "\n",
    "dataset_train = TripletsDataset(imagename_id_mapping_train, transform=None)\n",
    "dataset_valid = TripletsDataset(imagename_id_mapping_valid, transform=None)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=128,\n",
    "                              shuffle=True, num_workers=4)\n",
    "\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=128,\n",
    "                              shuffle=True, num_workers=4)\n",
    "#gen_tr = gen(sample_gen(file_id_mapping_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9345b5a73ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train'：\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics      \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # load best model \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
